{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOpKq8qZ678ejCuOWLFeulE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Raiaki3400/test/blob/main/preprocessing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_iEimInzRHVP",
        "outputId": "a6933420-81ee-42de-bd38-8efdb559ff33"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading LJ Speech dataset...\n",
            "Extracting LJ Speech dataset...\n",
            "Error extracting the dataset: not a bzip2 file\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import shutil\n",
        "import tarfile\n",
        "import requests\n",
        "\n",
        "# Function to download and extract LJ Speech dataset\n",
        "def download_ljspeech_dataset(data_dir):\n",
        "    lj_url = \"https://data.keithito.com/data/speech/LJSpeech-1.1.tar.bz2\"\n",
        "    lj_tar_file = os.path.join(data_dir, \"LJSpeech-1.1.tar.bz2\")\n",
        "\n",
        "    # Download LJ Speech dataset\n",
        "    print(\"Downloading LJ Speech dataset...\")\n",
        "    try:\n",
        "        response = requests.get(lj_url, stream=True)\n",
        "        with open(lj_tar_file, \"wb\") as f:\n",
        "            shutil.copyfileobj(response.raw, f)\n",
        "    except Exception as e:\n",
        "        print(\"Error downloading the dataset:\", e)\n",
        "        return\n",
        "\n",
        "    # Extract the tar file\n",
        "    print(\"Extracting LJ Speech dataset...\")\n",
        "    try:\n",
        "        with tarfile.open(lj_tar_file, \"r:bz2\") as tar:\n",
        "            tar.extractall(path=data_dir)\n",
        "    except tarfile.ReadError as e:\n",
        "        print(\"Error extracting the dataset:\", e)\n",
        "        return\n",
        "\n",
        "# Define directory to store dataset\n",
        "data_dir = \"datasets\"\n",
        "\n",
        "# Create directory if it doesn't exist\n",
        "os.makedirs(data_dir, exist_ok=True)\n",
        "\n",
        "# Download and extract LJ Speech dataset\n",
        "download_ljspeech_dataset(data_dir)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import librosa\n",
        "import numpy as np\n",
        "\n",
        "# Define functions for data preprocessing steps\n",
        "\n",
        "def data_cleaning(audio_data, sr):\n",
        "    # Example: Remove silence\n",
        "    trimmed_audio, _ = librosa.effects.trim(audio_data)\n",
        "    return trimmed_audio\n",
        "\n",
        "def normalization(audio_data):\n",
        "    # Example: Scale audio to have maximum absolute amplitude of 1\n",
        "    max_amp = np.max(np.abs(audio_data))\n",
        "    normalized_audio = audio_data / max_amp\n",
        "    return normalized_audio\n",
        "\n",
        "def augmentation(audio_data, sr):\n",
        "    # Example: Pitch shifting\n",
        "    pitched_audio = librosa.effects.pitch_shift(audio_data, sr, n_steps=2)\n",
        "    return pitched_audio\n",
        "\n",
        "# Load audio file\n",
        "file_path = \"/content/Test.wav\"\n",
        "audio_data, sr = librosa.load(file_path, sr=None)\n",
        "\n",
        "# Preprocess the audio data\n",
        "cleaned_audio = data_cleaning(audio_data, sr)\n",
        "normalized_audio = normalization(cleaned_audio)\n",
        "augmented_audio = augmentation(normalized_audio, sr)\n",
        "\n",
        "# Save preprocessed audio to a new file\n",
        "output_path = \"preprocessed_audio.wav\"\n",
        "librosa.output.write_wav(output_path, augmented_audio, sr)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 404
        },
        "id": "l7uZQcpZUJZk",
        "outputId": "f79982ff-379e-4842-e781-55a143934ccb"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-100d02f56bef>:24: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio_data, sr = librosa.load(file_path, sr=None)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "pitch_shift() takes 1 positional argument but 2 positional arguments (and 1 keyword-only argument) were given",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-100d02f56bef>\u001b[0m in \u001b[0;36m<cell line: 29>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0mcleaned_audio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_cleaning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maudio_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0mnormalized_audio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnormalization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcleaned_audio\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m \u001b[0maugmented_audio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maugmentation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnormalized_audio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;31m# Save preprocessed audio to a new file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-100d02f56bef>\u001b[0m in \u001b[0;36maugmentation\u001b[0;34m(audio_data, sr)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0maugmentation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maudio_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;31m# Example: Pitch shifting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mpitched_audio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlibrosa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meffects\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpitch_shift\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maudio_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mpitched_audio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: pitch_shift() takes 1 positional argument but 2 positional arguments (and 1 keyword-only argument) were given"
          ]
        }
      ]
    }
  ]
}